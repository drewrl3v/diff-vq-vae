{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Originals and Recons on the data-set level\n",
    "\n",
    "## This will be used for BUAN score comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from models import AllModels\n",
    "from dipy.segment.bundles import bundle_shape_similarity\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for every model\n",
    "batch_size = 256\n",
    "num_training_updates = 30_000\n",
    "num_epochs = 1\n",
    "\n",
    "num_hiddens = 128\n",
    "num_residual_hiddens = 32\n",
    "num_residual_layers = 2\n",
    "\n",
    "embedding_dim = 64\n",
    "num_embeddings = 512\n",
    "\n",
    "commitment_cost = 0.25\n",
    "\n",
    "decay = 0.99\n",
    "tau = 10.0\n",
    "std = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = torch.load('data_ml/val_set.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Note:\n",
    "\n",
    "The `recons` and `originals` directory will be used for the dataset as is.\n",
    "\n",
    "However the `subject_recons`, `subject_originals` will accumulate the originals across the subjects to reconstruct the entire bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect corresponding tracts\n",
    "tracts = {}\n",
    "\n",
    "for i, (tract, label) in enumerate(val_set):\n",
    "    subject, name_of_tract = label.split('__')\n",
    "\n",
    "    if subject in tracts:\n",
    "        tracts[subject].append([name_of_tract, tract])\n",
    "    else:\n",
    "        tracts[subject] = []\n",
    "        tracts[subject].append([name_of_tract, tract])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tracts_per_sub = []\n",
    "for subject in tracts.keys():\n",
    "    hold = set()\n",
    "    for name_of_tract, _ in tracts[subject]:\n",
    "        hold.add(name_of_tract)\n",
    "    num_tracts_per_sub.append((len(hold), subject))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tracts_per_sub.sort(key=lambda x:x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 'sub-1178')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tracts_per_sub[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194\n"
     ]
    }
   ],
   "source": [
    "tracts['sub-1178'][0]\n",
    "print(len(tracts['sub-1178']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring Models\n"
     ]
    }
   ],
   "source": [
    "# Test all 6 models\n",
    "print('Configuring Models')\n",
    "configs_to_run = [[False for _ in range(5)] for _ in range(5)]\n",
    "for i in range(5): \n",
    "    for j in range(5):\n",
    "        if j == i:\n",
    "            configs_to_run[i][j] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_full_tract(configs_to_run, subject):\n",
    "    for config in configs_to_run:\n",
    "        # current configuration\n",
    "        ae = config[0]; vae = config[1]; vq=config[2]; vq_ema = config[3]; vq_diff = config[4]\n",
    "\n",
    "        model = AllModels(num_hiddens, num_residual_layers, num_residual_hiddens,\n",
    "            num_embeddings, embedding_dim, commitment_cost, tau, std, decay, \n",
    "            ae, vae, vq, vq_ema, vq_diff\n",
    "            ).to(device)\n",
    "\n",
    "        if ae:\n",
    "            model.load_state_dict(torch.load('saved_models/ae.pt'))\n",
    "        elif vae:\n",
    "            model.load_state_dict(torch.load('saved_models/vae.pt'))\n",
    "        elif vq:\n",
    "            model.load_state_dict(torch.load('saved_models/vq.pt'))\n",
    "        elif vq_ema:\n",
    "            model.load_state_dict(torch.load('saved_models/vq_ema.pt'))\n",
    "        else:\n",
    "            model.load_state_dict(torch.load('saved_models/vq_diff.pt'))\n",
    "\n",
    "        m = model.eval()\n",
    "        print(m.model_used())\n",
    "\n",
    "        recons = {}\n",
    "        originals = {}\n",
    "        for label, x in subject:\n",
    "\n",
    "            # Keep a record of the original tract and express as numpy\n",
    "            if label in originals:\n",
    "                originals[label].append(x.permute(1,0,2).detach().cpu().numpy())\n",
    "            else:\n",
    "                originals[label] = [x.permute(1,0,2).detach().cpu().numpy()]\n",
    "            \n",
    "            # Then reconstruct\n",
    "            x = x.to(device).unsqueeze(0)\n",
    "            vq_loss, x_recon, perplexity, encodings = m(x)\n",
    "            x_recon = x_recon.squeeze(0)\n",
    "\n",
    "            # Keep a record of the recon tract and exress as numpy\n",
    "            if label in recons:\n",
    "                recons[label].append(x_recon.permute(1,0,2).detach().cpu().numpy())\n",
    "            else:\n",
    "                recons[label] = [x_recon.permute(1,0,2).detach().cpu().numpy()]\n",
    "\n",
    "        # concatenate the full reconstruction \n",
    "        for label in originals.keys():\n",
    "\n",
    "            originals[label] = np.concatenate(originals[label])\n",
    "            np.save(f'./subject_originals/{label}.npy', originals[label])\n",
    "\n",
    "            recons[label] = np.concatenate(recons[label])\n",
    "            np.save(f'./subject_recons/{label}_{m.model_used()}.npy', recons[label])\n",
    "\n",
    "\n",
    "        # Free up memory\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae\n",
      "vae\n",
      "vq\n",
      "vq_ema\n",
      "vq_diff\n"
     ]
    }
   ],
   "source": [
    "#reconstruct_full_tract(configs_to_run, tracts['sub-1178'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
